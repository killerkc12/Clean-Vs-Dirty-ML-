{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-briefing",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:27.672191Z",
     "iopub.status.busy": "2021-04-22T06:18:27.671538Z",
     "iopub.status.idle": "2021-04-22T06:18:28.425863Z",
     "shell.execute_reply": "2021-04-22T06:18:28.425022Z"
    },
    "papermill": {
     "duration": 0.785998,
     "end_time": "2021-04-22T06:18:28.426057",
     "exception": false,
     "start_time": "2021-04-22T06:18:27.640059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# Load everything that may be needed\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "import imageio\n",
    "import cv2 \n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-savannah",
   "metadata": {
    "papermill": {
     "duration": 0.018236,
     "end_time": "2021-04-22T06:18:28.463601",
     "exception": false,
     "start_time": "2021-04-22T06:18:28.445365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Store the paths for the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-relief",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:28.506690Z",
     "iopub.status.busy": "2021-04-22T06:18:28.505979Z",
     "iopub.status.idle": "2021-04-22T06:18:28.509070Z",
     "shell.execute_reply": "2021-04-22T06:18:28.508586Z"
    },
    "papermill": {
     "duration": 0.02677,
     "end_time": "2021-04-22T06:18:28.509219",
     "exception": false,
     "start_time": "2021-04-22T06:18:28.482449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_messy = \"./input/images/train/messy/\"\n",
    "train_clean= \"./input/images/train/clean\"\n",
    "test_messy= \"./input/images/val/messy\"\n",
    "test_clean= \"./input/images/val/clean\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-television",
   "metadata": {
    "papermill": {
     "duration": 0.018393,
     "end_time": "2021-04-22T06:18:28.546624",
     "exception": false,
     "start_time": "2021-04-22T06:18:28.528231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### To load the datasets\n",
    "The train and test images are taken and stored as 'X'. Also, there corresponding 'Y' values are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-thesaurus",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:28.598478Z",
     "iopub.status.busy": "2021-04-22T06:18:28.597450Z",
     "iopub.status.idle": "2021-04-22T06:18:28.600618Z",
     "shell.execute_reply": "2021-04-22T06:18:28.600052Z"
    },
    "papermill": {
     "duration": 0.035512,
     "end_time": "2021-04-22T06:18:28.600755",
     "exception": false,
     "start_time": "2021-04-22T06:18:28.565243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \n",
    "    train_set_x_orig_list,train_set_y_list, test_set_x_orig_list, test_set_y_list=[],[],[],[]\n",
    "\n",
    "    for image in (os.listdir(train_messy)): \n",
    "        path = os.path.join(train_messy, image)\n",
    "        img = cv2.imread(path) \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        train_set_x_orig_list.append(img)\n",
    "        train_set_y_list.append(0)\n",
    "\n",
    "    for image in (os.listdir(train_clean)): \n",
    "        path = os.path.join(train_clean, image)\n",
    "        img = cv2.imread(path) \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        train_set_x_orig_list.append(img)\n",
    "        train_set_y_list.append(1)\n",
    "\n",
    "    for image in (os.listdir(test_messy)): \n",
    "        path = os.path.join(test_messy, image)\n",
    "        img = cv2.imread(path) \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        test_set_x_orig_list.append(img)\n",
    "        test_set_y_list.append(0)\n",
    "\n",
    "    for image in (os.listdir(test_clean)): \n",
    "        path = os.path.join(test_clean, image)\n",
    "        img = cv2.imread(path) \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        test_set_x_orig_list.append(img)\n",
    "        test_set_y_list.append(1)\n",
    "\n",
    "    train_set_x_orig=np.array(train_set_x_orig_list)\n",
    "    train_set_y=np.array(train_set_y_list)\n",
    "    train_set_y=train_set_y.reshape((1,train_set_y.shape[0]))\n",
    "\n",
    "    test_set_x_orig=np.array(test_set_x_orig_list)\n",
    "    test_set_y=np.array(test_set_y_list)\n",
    "    test_set_y=test_set_y.reshape((1,test_set_y.shape[0]))\n",
    "\n",
    "    classes_list=[b'messy',b'clean']\n",
    "    classes=np.array(classes_list)\n",
    "    \n",
    "    return train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-dividend",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:28.643133Z",
     "iopub.status.busy": "2021-04-22T06:18:28.642467Z",
     "iopub.status.idle": "2021-04-22T06:18:32.004797Z",
     "shell.execute_reply": "2021-04-22T06:18:32.005290Z"
    },
    "papermill": {
     "duration": 3.385804,
     "end_time": "2021-04-22T06:18:32.005500",
     "exception": false,
     "start_time": "2021-04-22T06:18:28.619696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y,classes=load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-injury",
   "metadata": {
    "papermill": {
     "duration": 0.019143,
     "end_time": "2021-04-22T06:18:32.044775",
     "exception": false,
     "start_time": "2021-04-22T06:18:32.025632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### To check for a clean room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-planet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:32.107936Z",
     "iopub.status.busy": "2021-04-22T06:18:32.107192Z",
     "iopub.status.idle": "2021-04-22T06:18:32.299611Z",
     "shell.execute_reply": "2021-04-22T06:18:32.299047Z"
    },
    "papermill": {
     "duration": 0.235682,
     "end_time": "2021-04-22T06:18:32.299751",
     "exception": false,
     "start_time": "2021-04-22T06:18:32.064069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 100\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-trade",
   "metadata": {
    "papermill": {
     "duration": 0.021984,
     "end_time": "2021-04-22T06:18:32.344717",
     "exception": false,
     "start_time": "2021-04-22T06:18:32.322733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### To check for a messy room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-friend",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:32.418623Z",
     "iopub.status.busy": "2021-04-22T06:18:32.417949Z",
     "iopub.status.idle": "2021-04-22T06:18:32.576886Z",
     "shell.execute_reply": "2021-04-22T06:18:32.577394Z"
    },
    "papermill": {
     "duration": 0.210354,
     "end_time": "2021-04-22T06:18:32.577571",
     "exception": false,
     "start_time": "2021-04-22T06:18:32.367217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 10\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-raleigh",
   "metadata": {
    "papermill": {
     "duration": 0.025829,
     "end_time": "2021-04-22T06:18:32.629921",
     "exception": false,
     "start_time": "2021-04-22T06:18:32.604092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Find the values for:\n",
    "\n",
    "- m_train (number of training examples)\n",
    "- m_test (number of test examples)\n",
    "- num_px (= height = width of a training image)\n",
    "Remember that train_set_x_orig is a numpy-array of shape (m_train, num_px, num_px, 3). For instance, you can access m_train by writing train_set_x_orig.shape[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-chorus",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:32.693395Z",
     "iopub.status.busy": "2021-04-22T06:18:32.692292Z",
     "iopub.status.idle": "2021-04-22T06:18:32.698622Z",
     "shell.execute_reply": "2021-04-22T06:18:32.699281Z"
    },
    "papermill": {
     "duration": 0.043185,
     "end_time": "2021-04-22T06:18:32.699594",
     "exception": false,
     "start_time": "2021-04-22T06:18:32.656409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-portuguese",
   "metadata": {
    "papermill": {
     "duration": 0.025861,
     "end_time": "2021-04-22T06:18:32.752288",
     "exception": false,
     "start_time": "2021-04-22T06:18:32.726427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num_px $*$ num_px $*$ 3, 1).\n",
    "\n",
    "A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$*$c$*$d, a) is to use:\n",
    "\n",
    "X_flatten = X.reshape(X.shape[0], -1).T      # X.T is the transpose of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-schedule",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:32.813756Z",
     "iopub.status.busy": "2021-04-22T06:18:32.813041Z",
     "iopub.status.idle": "2021-04-22T06:18:32.817259Z",
     "shell.execute_reply": "2021-04-22T06:18:32.817791Z"
    },
    "papermill": {
     "duration": 0.03906,
     "end_time": "2021-04-22T06:18:32.817977",
     "exception": false,
     "start_time": "2021-04-22T06:18:32.778917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], num_px*num_px*3).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "# print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-latter",
   "metadata": {
    "papermill": {
     "duration": 0.026717,
     "end_time": "2021-04-22T06:18:32.871710",
     "exception": false,
     "start_time": "2021-04-22T06:18:32.844993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.\n",
    "\n",
    "One common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel).\n",
    "\n",
    "Let's standardize our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-working",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:32.931363Z",
     "iopub.status.busy": "2021-04-22T06:18:32.930657Z",
     "iopub.status.idle": "2021-04-22T06:18:33.138651Z",
     "shell.execute_reply": "2021-04-22T06:18:33.139159Z"
    },
    "papermill": {
     "duration": 0.240678,
     "end_time": "2021-04-22T06:18:33.139365",
     "exception": false,
     "start_time": "2021-04-22T06:18:32.898687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten/255.\n",
    "test_set_x = test_set_x_flatten/255.\n",
    "print('number of train datasets =' + str(train_set_x.shape))\n",
    "print('number of test datasets =' + str (test_set_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-flour",
   "metadata": {
    "papermill": {
     "duration": 0.027088,
     "end_time": "2021-04-22T06:18:33.193959",
     "exception": false,
     "start_time": "2021-04-22T06:18:33.166871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### To estimate the percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-bradley",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:33.256730Z",
     "iopub.status.busy": "2021-04-22T06:18:33.255811Z",
     "iopub.status.idle": "2021-04-22T06:18:33.260380Z",
     "shell.execute_reply": "2021-04-22T06:18:33.259800Z"
    },
    "papermill": {
     "duration": 0.039282,
     "end_time": "2021-04-22T06:18:33.260525",
     "exception": false,
     "start_time": "2021-04-22T06:18:33.221243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('% of Messy in the training data: ', 100*np.sum(train_set_y == 0)/len(train_set_y[0]))\n",
    "print('% of Clean in the training data: ', 100*np.sum(train_set_y == 1)/len(train_set_y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-appreciation",
   "metadata": {
    "papermill": {
     "duration": 0.027255,
     "end_time": "2021-04-22T06:18:33.315505",
     "exception": false,
     "start_time": "2021-04-22T06:18:33.288250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "The main steps for building a Neural Network are:\n",
    "\n",
    "Define the model structure (such as number of input features)\n",
    "Initialize the model's parameters\n",
    "Loop:\n",
    "Calculate current loss (forward propagation)\n",
    "Calculate current gradient (backward propagation)\n",
    "Update parameters (gradient descent)\n",
    "You often build 1-3 separately and integrate them into one function we call model()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-access",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:33.392437Z",
     "iopub.status.busy": "2021-04-22T06:18:33.391624Z",
     "iopub.status.idle": "2021-04-22T06:18:33.395745Z",
     "shell.execute_reply": "2021-04-22T06:18:33.395093Z"
    },
    "papermill": {
     "duration": 0.05252,
     "end_time": "2021-04-22T06:18:33.395895",
     "exception": false,
     "start_time": "2021-04-22T06:18:33.343375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0.\n",
    "    return w, b\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    m = X.shape[1]\n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    A = A.astype(np.float64)\n",
    "    cost = -1/m*np.sum(np.nan_to_num(Y*np.log(A)+(1-Y)*np.log(1-A)),axis=1)  \n",
    "    dw = 1/m*np.dot(X,(A-Y).T)\n",
    "    db = 1/m*np.sum(A-Y)  \n",
    "    cost = np.squeeze(np.array(cost))\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}    \n",
    "    return grads, cost\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, print_cost=False):\n",
    "    w = copy.deepcopy(w)\n",
    "    b = copy.deepcopy(b)  \n",
    "    costs = []    \n",
    "    for i in range(num_iterations): \n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        w = w-learning_rate*dw\n",
    "        b = b-learning_rate*db \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            if print_cost:\n",
    "                print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    return params, grads, costs\n",
    "\n",
    "def predict(w, b, X):\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0,i]<=0.5:\n",
    "            Y_prediction[0,i]=0\n",
    "        else:\n",
    "            Y_prediction[0,i]=1\n",
    "    return Y_prediction\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "    parameters, grads, costs = optimize(w,b,X_train,Y_train,num_iterations,learning_rate,print_cost)\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    Y_prediction_test = predict(w,b,X_test)\n",
    "    Y_prediction_train = predict(w,b,X_train)\n",
    "    if print_cost:\n",
    "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-cover",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:18:33.457444Z",
     "iopub.status.busy": "2021-04-22T06:18:33.456751Z",
     "iopub.status.idle": "2021-04-22T06:19:33.022583Z",
     "shell.execute_reply": "2021-04-22T06:19:33.023769Z"
    },
    "papermill": {
     "duration": 59.599958,
     "end_time": "2021-04-22T06:19:33.024121",
     "exception": false,
     "start_time": "2021-04-22T06:18:33.424163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 1500, learning_rate = 0.01, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-waste",
   "metadata": {
    "papermill": {
     "duration": 0.054046,
     "end_time": "2021-04-22T06:19:33.139492",
     "exception": false,
     "start_time": "2021-04-22T06:19:33.085446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train Accuracy of 100.0%\n",
    "### Test Accuracy of 60.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-empty",
   "metadata": {
    "papermill": {
     "duration": 0.033076,
     "end_time": "2021-04-22T06:19:33.205886",
     "exception": false,
     "start_time": "2021-04-22T06:19:33.172810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Plot the cost function and the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-jordan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:19:33.337202Z",
     "iopub.status.busy": "2021-04-22T06:19:33.286101Z",
     "iopub.status.idle": "2021-04-22T06:19:33.447296Z",
     "shell.execute_reply": "2021-04-22T06:19:33.446766Z"
    },
    "papermill": {
     "duration": 0.207864,
     "end_time": "2021-04-22T06:19:33.447465",
     "exception": false,
     "start_time": "2021-04-22T06:19:33.239601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-copper",
   "metadata": {
    "papermill": {
     "duration": 0.034228,
     "end_time": "2021-04-22T06:19:33.515794",
     "exception": false,
     "start_time": "2021-04-22T06:19:33.481566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test your own image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-ordinary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:19:33.593079Z",
     "iopub.status.busy": "2021-04-22T06:19:33.591962Z",
     "iopub.status.idle": "2021-04-22T06:19:33.595705Z",
     "shell.execute_reply": "2021-04-22T06:19:33.595088Z"
    },
    "papermill": {
     "duration": 0.045721,
     "end_time": "2021-04-22T06:19:33.595869",
     "exception": false,
     "start_time": "2021-04-22T06:19:33.550148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ownimage(my_image):\n",
    "    # We preprocess the image to fit your algorithm.\n",
    "    fname = my_image\n",
    "    image = np.array(Image.open(fname).resize((num_px, num_px)))\n",
    "    # plt.imshow(image)\n",
    "    \n",
    "    image = image / 255.\n",
    "    image = image.reshape((1, num_px * num_px * 3)).T\n",
    "    my_predicted_image = predict(d[\"w\"], d[\"b\"], image)\n",
    "    # plt.title(classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\"))\n",
    "    result = classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\")\n",
    "    # print(output)\n",
    "    return image, result\n",
    "\n",
    "    # print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-poster",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-22T06:19:33.671234Z",
     "iopub.status.busy": "2021-04-22T06:19:33.670445Z",
     "iopub.status.idle": "2021-04-22T06:19:33.971418Z",
     "shell.execute_reply": "2021-04-22T06:19:33.970848Z"
    },
    "papermill": {
     "duration": 0.340716,
     "end_time": "2021-04-22T06:19:33.971557",
     "exception": false,
     "start_time": "2021-04-22T06:19:33.630841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = \"./input/images/test/1.png\"\n",
    "# ownimage(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ownimage, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6edc2f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open(\"model.pkl\", \"rb\"))\n",
    "image, result = model(img)\n",
    "print(result)\n",
    "# plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a0983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c5b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1b532cdceb6376a4c42e6e5ce731586efab02ca710b01210cfcda4686ab3dda"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 76.963821,
   "end_time": "2021-04-22T06:19:36.050957",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-22T06:18:19.087136",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
